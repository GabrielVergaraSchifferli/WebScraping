{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paquetes necesarios\n",
    "\n",
    "import csv # para escribir .csv\n",
    "import pandas as pd # para manejo de estructuras pandas DataFrame\n",
    "import os  # para leer .csv\n",
    "import time # se importa sleep para pausar el código en tiempo controlado\n",
    "from time import sleep\n",
    "from getpass import getpass #escribir contraseña oculta\n",
    "# Paquetes para utilizar navegador\n",
    "from msedge.selenium_tools import Edge, EdgeOptions  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.common import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de funciones:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea la instancia para abrir el webbrowser MS EDGE\n",
    "def create_webdriver_instance():\n",
    "    options = EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    driver = Edge(options=options)\n",
    "    return driver\n",
    "\n",
    "# Ingresa a la pagina de twitter, ingresa credenciales, si falla devuelve error y detiene la operación. Entra y luego va a la pestaña home\n",
    "def login_to_twitter(username, password, driver):\n",
    "    url = 'https://twitter.com/login'\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        xpath_username = '//input[@name=\"session[username_or_email]\"]'\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.presence_of_element_located((By.XPATH, xpath_username)))\n",
    "        uid_input = driver.find_element_by_xpath(xpath_username)\n",
    "        uid_input.send_keys(username)\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for Login screen\")\n",
    "        return False\n",
    "\n",
    "    pwd_input = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "    pwd_input.send_keys(password)\n",
    "    try:\n",
    "        pwd_input.send_keys(Keys.RETURN)\n",
    "        url = \"https://twitter.com/home\"\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.url_to_be(url))\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for home screen\")\n",
    "    return True\n",
    "\n",
    "#ingresa el término de busqueda a la casilla de búsqueda de twitter\n",
    "\n",
    "## !!!!!!!!!! si twitter esta en ingles el área de búsqueda tiene un valor de \"Search query\"\n",
    "## pero en español tiene un valor de \"Búsqueda\"\n",
    "def find_search_input_and_enter_criteria(search_term, driver):\n",
    "    xpath_search = '//input[@aria-label=\"Search query\"]'  # Inglés: Search query, Españo : Búsqueda\n",
    "    search_input = driver.find_element_by_xpath(xpath_search)\n",
    "    search_input.send_keys(search_term)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    return True\n",
    "\n",
    "\n",
    "# cliquea la opcion \"tab_name\", se utiliza para ir a la opción \"Latest\", de los tweets \n",
    "def change_page_sort(tab_name, driver):\n",
    "    \"\"\"Options for this program are `Latest` and `Top`\"\"\"\n",
    "    tab = driver.find_element_by_link_text(tab_name)\n",
    "    tab.click()\n",
    "    xpath_tab_state = f'//a[contains(text(),\\\"{tab_name}\\\") and @aria-selected=\\\"true\\\"]'\n",
    "\n",
    "# genera id de tweet para identificalo y ver que no se repita  \n",
    "def generate_tweet_id(tweet):\n",
    "    return ''.join(tweet)\n",
    "\n",
    "# operación de scrolling retiene la última posición para comparar si se movió o no y así detener la operación\n",
    "# tiene los parámetros de tiempo que espera para realizar el scroll ( para que cargue la página)\n",
    "# max_attempts es el número de intentos de scrolling para detener la operación\n",
    "# cuando exede el número de intentos se detiene, esto para cuando se llegue al final de la cadena de búsqueda\n",
    "#  num_seconds_to_load es el tiempo que espera para realizar el scroll, entonces si carga rápido la pagina se puede reducir, si tarda en cargar se puede aumentar\n",
    "def scroll_down_page(driver, last_position, num_seconds_to_load=2, scroll_attempt=0, max_attempts=5):\n",
    "    \"\"\"The function will try to scroll down the page and will check the current\n",
    "    and last positions as an indicator. If the current and last positions are the same after `max_attempts`\n",
    "    the assumption is that the end of the scroll region has been reached and the `end_of_scroll_region`\n",
    "    flag will be returned as `True`\"\"\"\n",
    "    end_of_scroll_region = False\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # (0 , document.body.scrollHeight) son las coordenadas para mover la barra de scroll\n",
    "    sleep(num_seconds_to_load)\n",
    "    curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    if curr_position == last_position:\n",
    "        if scroll_attempt < max_attempts:\n",
    "            end_of_scroll_region = True\n",
    "        else:\n",
    "            scroll_down_page(last_position, curr_position, scroll_attempt + 1) # se compara la posición para ver si se está moviendo o no, de forma de determinar si se llega al final\n",
    "    last_position = curr_position\n",
    "    return last_position, end_of_scroll_region\n",
    "\n",
    "#guarda el tweet\n",
    "def save_tweet_data_to_csv(records, filepath, mode='a+'):\n",
    "    header = ['User', 'Handle', 'PostDate', 'TweetText', 'ReplyCount', 'RetweetCount', 'LikeCount']\n",
    "    with open(filepath, mode=mode, newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if mode == 'w':\n",
    "            writer.writerow(header)\n",
    "        if records:\n",
    "            writer.writerow(records)\n",
    "# extrae todos los tweets que hay cargados en la página, para despues realizar el scroll e iterar nuevamente\n",
    "# twitter carga dinámicamente los tweets en el código html, entonces para que sean cargados a la página se debe\n",
    "# realizar el scroll, de otra forma no se cargan.\n",
    "def collect_all_tweets_from_current_view(driver, lookback_limit=25):\n",
    "    \"\"\"The page is continously loaded, so as you scroll down the number of tweets returned by this function will\n",
    "     continue to grow. To limit the risk of 're-processing' the same tweet over and over again, you can set the\n",
    "     `lookback_limit` to only process the last `x` number of tweets extracted from the page in each iteration.\n",
    "     You may need to play around with this number to get something that works for you. I've set the default\n",
    "     based on my computer settings and internet speed, etc...\"\"\"\n",
    "    page_cards = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')\n",
    "    if len(page_cards) <= lookback_limit:\n",
    "        return page_cards\n",
    "    else:\n",
    "        return page_cards[-lookback_limit:]\n",
    "\n",
    "# extrae la información del tweet\n",
    "def extract_data_from_current_tweet_card(card):\n",
    "    try:\n",
    "        user = card.find_element_by_xpath('.//span').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        user = \"\"\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        return\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        handle = \"\"\n",
    "    try:\n",
    "        \"\"\"\n",
    "        If there is no post date here, there it is usually sponsored content, or some\n",
    "        other form of content where post dates do not apply. You can set a default value\n",
    "        for the postdate on Exception if you which to keep this record. By default I am\n",
    "        excluding these.\n",
    "        \"\"\"\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        return\n",
    "    try:\n",
    "        _comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _comment = \"\"\n",
    "    try:\n",
    "        _responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _responding = \"\"\n",
    "    tweet_text = _comment + _responding\n",
    "    try:\n",
    "        reply_count = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        reply_count = \"\"\n",
    "    try:\n",
    "        retweet_count = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        retweet_count = \"\"\n",
    "    try:\n",
    "        like_count = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        like_count = \"\"\n",
    "\n",
    "    tweet = (user, handle, postdate, tweet_text, reply_count, retweet_count, like_count) # agregar reply_to\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDENCIALES\n",
    "url = 'https://twitter.com/login'\n",
    "\n",
    "username = \"usuario123\"            # nombre de usuario o correo\n",
    "password = \"clave123\"                 # contraseña\n",
    "filepath = '#EstásEstamos.csv'        # nombre de archivo de extracción (el nombre del .csv que se guarda)\n",
    "search_term = '#EstásEstamos'         # termino de busqueda ( se ingresa textual sin \" \" en la barra de búsqueda)\n",
    "page_sort = \"Latest\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Iniciar navegador**: se inicia la sesión de EDGE a través de Python.\n",
    "\n",
    "La función **create_webdriver_instance()** abre el navegador EDGE en este caso, guardar en variable **driver** para poder operar en él.\n",
    "\n",
    "El método **maximize_window()** maximiza la ventana del buscador, en este caso, **driver.maximize_window()** maximiza la ventana de driver.\n",
    "\n",
    "**driver.get(url)**  dirige el navegador hacia el url, en este caso url = 'https://twitter.com/login'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/ejemplo_xpath.png\" width=\"1000\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = create_webdriver_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.Ingerso de credenciales**\n",
    "\n",
    "**find_element_by_xpath**: esta función busca el elemento HTML en la dirección de su argumento. Opera sobre la variable driver creada anteriormente en paso 1. \n",
    "\n",
    "**send_keys** ingresa el argumento al objeto, en este caso, escribe el nombre de usuario en la dirección extraída por .find_element_by_xpath().\n",
    "\n",
    "**send_keys(Keys.RETURN)** presiona enter en la dirreción de operación.\n",
    "\n",
    "Para la búsqueda de la dirección xpath se puede realizar de diferentes maneras. Una forma es hacer clic derecho en el objeto de interés de la página y seleccióna insepccionar hasta que se tenga identificado la sección del código HTML del objeto. Luego, en el objeto de interés clic derecho y buscar opción copiar full xpath. Con esta dirección se utiliza como argumento en .find_element_by_xpath(). Otra forma de encontrar esta dirección es con \"//\", cuando está \"/\" solo, profundiza en el objeto. Cuando hay dos \"/\", o sea, \"//\" es buscar cualquier elemento en todo el código que tenga la opción de búsqueda deseada. En este caso, se quiere encontrar el objeto donde se introduce el nombre de usuario el cual es una clase de input, entonces \"//input\" busca todas las clases de input y se busca el caso particular que contenga \"name =\"session[username_or_email]\". Como es el único objeto input con este argumento no hay chance de confusión. Similar proceso para encontrar el ibjeto de input de contraseña.\n",
    "\n",
    "\n",
    "<img src=\"Imagenes/ejemplo_xpath.png\" width=\"1000\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"gabriel.vergara@sansano.usm.cl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_username = '//input[@name=\"session[username_or_email]\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath_username)\n",
    "uid_input.send_keys(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ··············\n"
     ]
    }
   ],
   "source": [
    "password = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd_input = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "pwd_input.send_keys(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd_input.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#login_to_twitter(username, password, driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Ingreso de campos de búsqueda avanzada** Se ingresa a la opción de búsqueda avanzada de Twitter.\n",
    "\n",
    "**Campos de búsqeuda avanzada**: Se tienen diversas opciones de búsqueda. El proceso de búsqueda de las direcciones de cada objeto es análogo al paso 2.\n",
    "\n",
    "En este caso, hay distintos tipos de clase para la búsqueda, ingresar texto, seleccionar opción(**Dropdown**) entre otras. En selección de idioma se tiene una objeto Dropdown, el cual se debe clickear y seleccionar la opción. Para esto, la búsqueda de dirección se puede realizar mediante find_element_by_xpath o con fin_element_by_id directamente. Una vez obtenida la dirección (driver.find_element_by_id(\"Language\") para este caso) se guarda en una variable y a esa variable se le aplica la función Select(driver.find_element_by_id(\"Language\")) para este caso. Esto abre las opciones múltiples del objeto y luego se debe realizar la selección. Para esto hay varios métodos, selecciónar por texto visible o por número de opción entre otras. Para el caso se realiza una selección por text visible select_by_visible_text( Select(driver.find_element_by_id(\"Language\")) ).\n",
    "\n",
    "Para el caso de la selección de fecha de búsqueda,  se puede realizar la búsqueda de dirección con find_element_by_id pero se tiene que hay dos objetos con el argumento \"Year\" dado que se tiene 2 entradas, From y To, por lo tanto hay que diferenciar entre ella. En este caso se utilizó find_element_by_xpath donde se copió la dirección xpath como se mencionó en 2. De esta forma se discrimina en cual de las dos opciones se esta buscando.\n",
    "\n",
    "Finalmente se busca la dirección del botón \"Search\" y se clickea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Campo: Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://twitter.com/search-advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_of_these_words = \" \"\n",
    "xpath = '//input[@name=\"allOfTheseWords\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(All_of_these_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "This_exact_phrase = \" \"\n",
    "xpath = '//input[@name=\"thisExactPhrase\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(This_exact_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Any_of_these_words = \"bancodechile bancochile bancosantander santanderchile bancobci bsantander bancoedwards bedwards banchile\"\n",
    "xpath = '//input[@name=\"anyOfTheseWords\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(Any_of_these_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "None_of_these_words = \" \"\n",
    "xpath = '//input[@name=\"noneOfTheseWords\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(None_of_these_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_Hashtags = \"#santanderchile #bancochile #estasestamos #bancoestado #bancobci\"\n",
    "xpath = '//input[@name=\"theseHashtags\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(these_Hashtags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_option = \"Any language\"\n",
    "xpath = \"Language\"\n",
    "uid_input = driver.find_element_by_id(xpath) # se busca elemento por id, no por xpath.\n",
    "select = Select(uid_input)\n",
    "select.select_by_visible_text(select_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Campo: Accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_these_accounts = \"@latercera\"\n",
    "xpath = '//input[@name=\"fromTheseAccounts\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(from_these_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_these_accounts = \" \"\n",
    "xpath = '//input[@name=\"toTheseAccounts\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(to_these_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentioning_these_accounts = \" \"\n",
    "xpath = '//input[@name=\"mentioningTheseAccounts\"]'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "uid_input.send_keys(mentioning_these_accounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Campo: Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_year = \"2006\"\n",
    "xpath = '/html/body/div/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div[2]/div/div/div/div[16]/div/div[2]/div/div[3]/select'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "select = Select(uid_input)\n",
    "select.select_by_visible_text(from_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_year = \"2021\"\n",
    "xpath = '/html/body/div/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div[2]/div/div/div/div[16]/div/div[4]/div/div[3]/select'\n",
    "uid_input = driver.find_element_by_xpath(xpath)\n",
    "select = Select(uid_input)\n",
    "select.select_by_visible_text(to_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalizar y ejecutar el filtro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_name = \"Search\"\n",
    "xpath = \"/html/body/div/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div[1]/div/div/div/div[3]/div/div/span\"\n",
    "driver.find_element_by_xpath(xpath).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ir a la tab Latest** la función change_page_sort(tab, driver) toma como argumento el driver definido en 1, y clickea la opción tab, en este caso se dirige a \"Latest\", también puede ser \"Top\" entre las opciones de Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_page_sort(\"Latest\", driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.Algoritmo de copia de tweets**: \n",
    "En esta sección se realiza la copia de los Tweets presentes en el código HTML, una vez hecha la copia se realiza el scrolling para generar más. La página de Twitter genera los tweets mostrados en pantalla dinámicamente, esto es, solo están los que se muestran en pantalla y unos pocos más en el código HTML, por esto para segui extrallendo mmas tweets es necesario bajar en la página. Como es posible que al bajar la página se muestren tweets anteriores, se genera un id de cada tweet de manera de identificar si se repiten o no para no tener duplciados en la extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores iniciales que requiere el algoritmo siguiente para ejecutarse\n",
    "save_tweet_data_to_csv(None, filepath, 'w') \n",
    "last_position = None\n",
    "end_of_scroll_region = False\n",
    "unique_tweets = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo de extracción**\n",
    "1. collect_all_tweets_from_current_view(driver): optiene las direcciones de todos los tweets cargados en el código. (cards)\n",
    "\n",
    "2. Iterar por todas las dirreciones de tweets: for card in cards \n",
    "    1. se extrae el tweet mediante extract_data_from_current_tweet_card(card)\n",
    "        1. retorna una lista con los contenidos del tweet como texto : (user, handle, postdate, tweet_text, reply_count, retweet_count, like_count)\n",
    "    2. tweet_id genera un id para identificar el tweet con el fin de evitar duplicados.\n",
    "        1. if tweet_id not in unique_tweets: unique_tweets comienza con una lista vacía, a medida que se van extrayendo tweets se añaden a la lista. Por lo tanto, si el tweet no está en la lista se añade, si esta no se añade-\n",
    "        2. despues de verificar unicidad del tweet, se genera un archivo .csv en el cual se guardan los tweets.    \n",
    "3. Se guardan las posiciones de la barra de scroll, para tener criterio de detención. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not end_of_scroll_region:\n",
    "    cards = collect_all_tweets_from_current_view(driver)\n",
    "    for card in cards:\n",
    "        try:\n",
    "            tweet = extract_data_from_current_tweet_card(card)\n",
    "        except exceptions.StaleElementReferenceException:\n",
    "            continue\n",
    "        if not tweet:\n",
    "            continue\n",
    "        tweet_id = generate_tweet_id(tweet)\n",
    "        if tweet_id not in unique_tweets:\n",
    "            unique_tweets.add(tweet_id)\n",
    "            save_tweet_data_to_csv(tweet, filepath)\n",
    "    last_position, end_of_scroll_region = scroll_down_page(driver, last_position,num_seconds_to_load=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
